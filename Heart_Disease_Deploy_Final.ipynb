{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c39e9f-ffc7-4b4f-892e-484c5423c8ed",
   "metadata": {},
   "source": [
    "Heart_Disease_ Deployment_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6558cd0-6146-4f06-a13a-5cbdd3dcace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.3)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kalajimi\\appdata\\local\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Best Parameters: {'class_weight': 'balanced_subsample', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Accuracy: 0.62\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        32\n",
      "           1       0.25      0.18      0.21        11\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.33      0.43      0.38         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.29      0.32      0.30        60\n",
      "weighted avg       0.53      0.62      0.57        60\n",
      "\n",
      "Accuracy: 0.92\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       160\n",
      "           1       0.88      0.83      0.86        54\n",
      "           2       0.88      0.80      0.84        35\n",
      "           3       0.84      0.89      0.86        35\n",
      "           4       0.91      0.77      0.83        13\n",
      "\n",
      "    accuracy                           0.92       297\n",
      "   macro avg       0.89      0.86      0.87       297\n",
      "weighted avg       0.92      0.92      0.92       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Install necessary packages:\n",
    "!pip install Flask joblib\n",
    "!pip install imbalanced-learn\n",
    "\n",
    "# 2. Model Training and Saving:\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Download and extract the dataset\n",
    "f_zip = 'https://archive.ics.uci.edu/static/public/45/heart+disease.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "heart_disease_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "heart_disease_zip.extractall()\n",
    "\n",
    "# Define column names and load the datasets\n",
    "col_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'class']\n",
    "urls = ['processed.cleveland.data', 'processed.hungarian.data', 'processed.switzerland.data', 'processed.va.data']\n",
    "dataFrames = [pd.read_csv(url, header=None, names=col_names, na_values='?') for url in urls]\n",
    "\n",
    "# Combine all data frames into one\n",
    "heart_disease_df = pd.concat(dataFrames, ignore_index=True)\n",
    "\n",
    "# Data Cleaning: Handle missing values\n",
    "heart_disease_df = heart_disease_df.dropna()\n",
    "\n",
    "# Define features and target\n",
    "X = heart_disease_df.drop(columns='class')\n",
    "y = heart_disease_df['class']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Use SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the model and parameter grid\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Get the best model and evaluate it\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save the model and the scaler\n",
    "joblib.dump(best_model, 'heart_disease_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# 3. Performing Predictions:\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and the scaler\n",
    "clf = joblib.load('heart_disease_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Load the test dataset (for demonstration purposes, using the same dataset)\n",
    "test = pd.read_csv('processed.cleveland.data', header=None, names=col_names, na_values='?')\n",
    "test = test.dropna()\n",
    "\n",
    "# Separate features and target for test data\n",
    "X_test = test.drop(columns='class')\n",
    "y_test = test['class']\n",
    "\n",
    "# Standardize the features\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for predictions\n",
    "predictions = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "predictions.head(10)\n",
    "\n",
    "# 4. Evaluating Predictions:\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e0465-8686-4c42-a6a2-adf6041316f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
